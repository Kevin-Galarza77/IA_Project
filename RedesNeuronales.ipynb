{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba05469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis, skew\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f26e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    x = pickle._Unpickler(open(filename,'rb'))\n",
    "    x.encoding = 'latin1'\n",
    "    p = x.load()\n",
    "    return p\n",
    "\n",
    "files = []\n",
    "for n in range(12,16):\n",
    "    s = 's'\n",
    "    if n<10:\n",
    "        s+='0'\n",
    "    s += str(n)+'.dat'\n",
    "    files.append(s)\n",
    "\n",
    "labels = []\n",
    "data   = []\n",
    "for i in files:\n",
    "    trial = read_file(i)\n",
    "    labels.append(trial['labels'])\n",
    "    data.append(trial['data'])\n",
    "    \n",
    "    \n",
    "labels = np.array(labels)\n",
    "labels = labels.flatten()\n",
    "labels = labels.reshape(160, 4)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "data = data.flatten()\n",
    "data = data.reshape(160, 40, 8064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4247de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1755f165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 40, 8064)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df739ce1",
   "metadata": {},
   "source": [
    "#  One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f065a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valenciaData = labels[:, :1]\n",
    "arousalData  = labels[:,1:2]\n",
    "medianValencia = np.median(valenciaData)\n",
    "medianArousle  = np.median(arousalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f8726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoding(valor,median):\n",
    "    if valor >= median:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75e578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFValencia = []\n",
    "for i in valenciaData:\n",
    "    DFValencia.append([OneHotEncoding(i[0],medianValencia)])\n",
    "    \n",
    "DFArousal = []\n",
    "for i in arousalData:\n",
    "    DFArousal.append([OneHotEncoding(i[0],medianArousle)])\n",
    "\n",
    "DFValencia = pd.DataFrame(data =DFValencia,columns=['Valence'])\n",
    "DFArousal = pd.DataFrame(data =DFArousal,columns=['Arousal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45e44f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Valence  Arousal\n",
       "0          1        1\n",
       "1          1        1\n",
       "2          1        1\n",
       "3          1        1\n",
       "4          0        1\n",
       "..       ...      ...\n",
       "155        0        0\n",
       "156        0        0\n",
       "157        0        1\n",
       "158        0        0\n",
       "159        0        1\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ETIQUETA VALENCIA Y ETIQUETA AROUSEL\n",
    "DFValenciaArrousel = pd.concat([DFValencia,DFArousal],axis=1)\n",
    "DFValenciaArrousel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0a9ed",
   "metadata": {},
   "source": [
    "# Considerar únicamente 32 de los 40 canales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2c1ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 32, 8064)\n"
     ]
    }
   ],
   "source": [
    "egg_data = []\n",
    "N=32\n",
    "for i in range (len(data)):\n",
    "    for j in range (N):\n",
    "        egg_data.append(data[i,j])\n",
    "egg_data = np.reshape(egg_data, (len(data),N,len(data[0,0]))) #(160, 32, 8064)\n",
    "print(egg_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15832d8e",
   "metadata": {},
   "source": [
    "# Extraer características de la data (media, varianza, mediana, curtosis,skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93e5cb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.136242</td>\n",
       "      <td>-0.230463</td>\n",
       "      <td>-0.485368</td>\n",
       "      <td>-0.191395</td>\n",
       "      <td>-0.101293</td>\n",
       "      <td>-0.149035</td>\n",
       "      <td>0.214239</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>0.270990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134745</td>\n",
       "      <td>-0.213549</td>\n",
       "      <td>-0.192078</td>\n",
       "      <td>-0.175423</td>\n",
       "      <td>-0.107930</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>-0.125412</td>\n",
       "      <td>0.324328</td>\n",
       "      <td>0.259344</td>\n",
       "      <td>0.265191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125861</td>\n",
       "      <td>-0.327134</td>\n",
       "      <td>-0.222775</td>\n",
       "      <td>-0.037336</td>\n",
       "      <td>-0.168785</td>\n",
       "      <td>-0.081766</td>\n",
       "      <td>-0.119669</td>\n",
       "      <td>0.322914</td>\n",
       "      <td>0.314184</td>\n",
       "      <td>0.348474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053120</td>\n",
       "      <td>-0.125716</td>\n",
       "      <td>-0.145243</td>\n",
       "      <td>-0.078934</td>\n",
       "      <td>-0.129396</td>\n",
       "      <td>-0.067172</td>\n",
       "      <td>-0.095273</td>\n",
       "      <td>0.140745</td>\n",
       "      <td>0.105676</td>\n",
       "      <td>0.187967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329096</td>\n",
       "      <td>-0.189732</td>\n",
       "      <td>-0.397356</td>\n",
       "      <td>-0.267826</td>\n",
       "      <td>-0.351554</td>\n",
       "      <td>-0.208562</td>\n",
       "      <td>-0.317293</td>\n",
       "      <td>0.453197</td>\n",
       "      <td>0.434129</td>\n",
       "      <td>0.491896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749911</td>\n",
       "      <td>-0.935890</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>-0.034464</td>\n",
       "      <td>-0.364933</td>\n",
       "      <td>-0.534069</td>\n",
       "      <td>0.096746</td>\n",
       "      <td>-0.423109</td>\n",
       "      <td>-0.314202</td>\n",
       "      <td>0.111795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821177</td>\n",
       "      <td>-0.843650</td>\n",
       "      <td>0.109154</td>\n",
       "      <td>-0.377837</td>\n",
       "      <td>-0.633505</td>\n",
       "      <td>-0.732398</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>-0.657737</td>\n",
       "      <td>-0.563958</td>\n",
       "      <td>0.154532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404489</td>\n",
       "      <td>-0.477506</td>\n",
       "      <td>0.034463</td>\n",
       "      <td>-0.176934</td>\n",
       "      <td>-0.180343</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-0.011187</td>\n",
       "      <td>-0.350077</td>\n",
       "      <td>-0.328384</td>\n",
       "      <td>0.044254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128420</td>\n",
       "      <td>-1.154964</td>\n",
       "      <td>-0.138953</td>\n",
       "      <td>-0.349398</td>\n",
       "      <td>-0.807273</td>\n",
       "      <td>-1.163223</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>-0.885491</td>\n",
       "      <td>-0.757759</td>\n",
       "      <td>0.288144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664642</td>\n",
       "      <td>-0.657028</td>\n",
       "      <td>0.059789</td>\n",
       "      <td>-0.026417</td>\n",
       "      <td>-0.399564</td>\n",
       "      <td>-0.691021</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>-0.471866</td>\n",
       "      <td>-0.302198</td>\n",
       "      <td>0.345745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "          7         8         9    ...       150       151       152  \\\n",
       "0    0.145142  0.002124 -0.159163  ...  0.147541 -0.136242 -0.230463   \n",
       "1   -0.118192 -0.046173  0.073946  ...  0.134745 -0.213549 -0.192078   \n",
       "2    0.228773  0.017037 -0.210503  ...  0.125861 -0.327134 -0.222775   \n",
       "3    0.085666  0.008473 -0.097937  ...  0.053120 -0.125716 -0.145243   \n",
       "4    0.106967 -0.070199 -0.146756  ...  0.329096 -0.189732 -0.397356   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.749911 -0.935890  0.037145   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.821177 -0.843650  0.109154   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.404489 -0.477506  0.034463   \n",
       "158  0.509372  0.196520  0.353393  ...  1.128420 -1.154964 -0.138953   \n",
       "159  0.352581  0.013532  0.110845  ...  0.664642 -0.657028  0.059789   \n",
       "\n",
       "          153       154       155       156       157       158       159  \n",
       "0   -0.485368 -0.191395 -0.101293 -0.149035  0.214239  0.229560  0.270990  \n",
       "1   -0.175423 -0.107930 -0.014033 -0.125412  0.324328  0.259344  0.265191  \n",
       "2   -0.037336 -0.168785 -0.081766 -0.119669  0.322914  0.314184  0.348474  \n",
       "3   -0.078934 -0.129396 -0.067172 -0.095273  0.140745  0.105676  0.187967  \n",
       "4   -0.267826 -0.351554 -0.208562 -0.317293  0.453197  0.434129  0.491896  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "155 -0.034464 -0.364933 -0.534069  0.096746 -0.423109 -0.314202  0.111795  \n",
       "156 -0.377837 -0.633505 -0.732398  0.015434 -0.657737 -0.563958  0.154532  \n",
       "157 -0.176934 -0.180343 -0.272553 -0.011187 -0.350077 -0.328384  0.044254  \n",
       "158 -0.349398 -0.807273 -1.163223  0.006002 -0.885491 -0.757759  0.288144  \n",
       "159 -0.026417 -0.399564 -0.691021  0.283223 -0.471866 -0.302198  0.345745  \n",
       "\n",
       "[160 rows x 160 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media     =  np.mean(egg_data, axis=2)\n",
    "varianza  =  np.var(egg_data, axis=2) \n",
    "mediana   =  np.median(egg_data, axis=2)\n",
    "curtosis  =  scipy.stats.kurtosis(egg_data, axis=2)\n",
    "asimetria =  scipy.stats.skew(egg_data, axis=2)\n",
    "totalData =  np.concatenate((media, varianza, mediana,curtosis,asimetria),axis=1) \n",
    "totalData =  pd.DataFrame(totalData)\n",
    "totalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98b02e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230463</td>\n",
       "      <td>-0.485368</td>\n",
       "      <td>-0.191395</td>\n",
       "      <td>-0.101293</td>\n",
       "      <td>-0.149035</td>\n",
       "      <td>0.214239</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>0.270990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192078</td>\n",
       "      <td>-0.175423</td>\n",
       "      <td>-0.107930</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>-0.125412</td>\n",
       "      <td>0.324328</td>\n",
       "      <td>0.259344</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222775</td>\n",
       "      <td>-0.037336</td>\n",
       "      <td>-0.168785</td>\n",
       "      <td>-0.081766</td>\n",
       "      <td>-0.119669</td>\n",
       "      <td>0.322914</td>\n",
       "      <td>0.314184</td>\n",
       "      <td>0.348474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145243</td>\n",
       "      <td>-0.078934</td>\n",
       "      <td>-0.129396</td>\n",
       "      <td>-0.067172</td>\n",
       "      <td>-0.095273</td>\n",
       "      <td>0.140745</td>\n",
       "      <td>0.105676</td>\n",
       "      <td>0.187967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397356</td>\n",
       "      <td>-0.267826</td>\n",
       "      <td>-0.351554</td>\n",
       "      <td>-0.208562</td>\n",
       "      <td>-0.317293</td>\n",
       "      <td>0.453197</td>\n",
       "      <td>0.434129</td>\n",
       "      <td>0.491896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>-0.034464</td>\n",
       "      <td>-0.364933</td>\n",
       "      <td>-0.534069</td>\n",
       "      <td>0.096746</td>\n",
       "      <td>-0.423109</td>\n",
       "      <td>-0.314202</td>\n",
       "      <td>0.111795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109154</td>\n",
       "      <td>-0.377837</td>\n",
       "      <td>-0.633505</td>\n",
       "      <td>-0.732398</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>-0.657737</td>\n",
       "      <td>-0.563958</td>\n",
       "      <td>0.154532</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034463</td>\n",
       "      <td>-0.176934</td>\n",
       "      <td>-0.180343</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-0.011187</td>\n",
       "      <td>-0.350077</td>\n",
       "      <td>-0.328384</td>\n",
       "      <td>0.044254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138953</td>\n",
       "      <td>-0.349398</td>\n",
       "      <td>-0.807273</td>\n",
       "      <td>-1.163223</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>-0.885491</td>\n",
       "      <td>-0.757759</td>\n",
       "      <td>0.288144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059789</td>\n",
       "      <td>-0.026417</td>\n",
       "      <td>-0.399564</td>\n",
       "      <td>-0.691021</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>-0.471866</td>\n",
       "      <td>-0.302198</td>\n",
       "      <td>0.345745</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "            7         8         9  ...       152       153       154  \\\n",
       "0    0.145142  0.002124 -0.159163  ... -0.230463 -0.485368 -0.191395   \n",
       "1   -0.118192 -0.046173  0.073946  ... -0.192078 -0.175423 -0.107930   \n",
       "2    0.228773  0.017037 -0.210503  ... -0.222775 -0.037336 -0.168785   \n",
       "3    0.085666  0.008473 -0.097937  ... -0.145243 -0.078934 -0.129396   \n",
       "4    0.106967 -0.070199 -0.146756  ... -0.397356 -0.267826 -0.351554   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.037145 -0.034464 -0.364933   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.109154 -0.377837 -0.633505   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.034463 -0.176934 -0.180343   \n",
       "158  0.509372  0.196520  0.353393  ... -0.138953 -0.349398 -0.807273   \n",
       "159  0.352581  0.013532  0.110845  ...  0.059789 -0.026417 -0.399564   \n",
       "\n",
       "          155       156       157       158       159  Valence  Arousal  \n",
       "0   -0.101293 -0.149035  0.214239  0.229560  0.270990        1        1  \n",
       "1   -0.014033 -0.125412  0.324328  0.259344  0.265191        1        1  \n",
       "2   -0.081766 -0.119669  0.322914  0.314184  0.348474        1        1  \n",
       "3   -0.067172 -0.095273  0.140745  0.105676  0.187967        1        1  \n",
       "4   -0.208562 -0.317293  0.453197  0.434129  0.491896        0        1  \n",
       "..        ...       ...       ...       ...       ...      ...      ...  \n",
       "155 -0.534069  0.096746 -0.423109 -0.314202  0.111795        0        0  \n",
       "156 -0.732398  0.015434 -0.657737 -0.563958  0.154532        0        0  \n",
       "157 -0.272553 -0.011187 -0.350077 -0.328384  0.044254        0        1  \n",
       "158 -1.163223  0.006002 -0.885491 -0.757759  0.288144        0        0  \n",
       "159 -0.691021  0.283223 -0.471866 -0.302198  0.345745        0        1  \n",
       "\n",
       "[160 rows x 162 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UNIMOS CON LA ETIQUETA VALENCIA Y ETIQUETA AROUSEL\n",
    "totalData = pd.concat([totalData,DFValenciaArrousel],axis=1)\n",
    "totalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "371b8064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "totalData.isnull()\n",
    "sns.heatmap(totalData.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0de7c26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230463</td>\n",
       "      <td>-0.485368</td>\n",
       "      <td>-0.191395</td>\n",
       "      <td>-0.101293</td>\n",
       "      <td>-0.149035</td>\n",
       "      <td>0.214239</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>0.270990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192078</td>\n",
       "      <td>-0.175423</td>\n",
       "      <td>-0.107930</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>-0.125412</td>\n",
       "      <td>0.324328</td>\n",
       "      <td>0.259344</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222775</td>\n",
       "      <td>-0.037336</td>\n",
       "      <td>-0.168785</td>\n",
       "      <td>-0.081766</td>\n",
       "      <td>-0.119669</td>\n",
       "      <td>0.322914</td>\n",
       "      <td>0.314184</td>\n",
       "      <td>0.348474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145243</td>\n",
       "      <td>-0.078934</td>\n",
       "      <td>-0.129396</td>\n",
       "      <td>-0.067172</td>\n",
       "      <td>-0.095273</td>\n",
       "      <td>0.140745</td>\n",
       "      <td>0.105676</td>\n",
       "      <td>0.187967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397356</td>\n",
       "      <td>-0.267826</td>\n",
       "      <td>-0.351554</td>\n",
       "      <td>-0.208562</td>\n",
       "      <td>-0.317293</td>\n",
       "      <td>0.453197</td>\n",
       "      <td>0.434129</td>\n",
       "      <td>0.491896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>-0.034464</td>\n",
       "      <td>-0.364933</td>\n",
       "      <td>-0.534069</td>\n",
       "      <td>0.096746</td>\n",
       "      <td>-0.423109</td>\n",
       "      <td>-0.314202</td>\n",
       "      <td>0.111795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109154</td>\n",
       "      <td>-0.377837</td>\n",
       "      <td>-0.633505</td>\n",
       "      <td>-0.732398</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>-0.657737</td>\n",
       "      <td>-0.563958</td>\n",
       "      <td>0.154532</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034463</td>\n",
       "      <td>-0.176934</td>\n",
       "      <td>-0.180343</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-0.011187</td>\n",
       "      <td>-0.350077</td>\n",
       "      <td>-0.328384</td>\n",
       "      <td>0.044254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138953</td>\n",
       "      <td>-0.349398</td>\n",
       "      <td>-0.807273</td>\n",
       "      <td>-1.163223</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>-0.885491</td>\n",
       "      <td>-0.757759</td>\n",
       "      <td>0.288144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059789</td>\n",
       "      <td>-0.026417</td>\n",
       "      <td>-0.399564</td>\n",
       "      <td>-0.691021</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>-0.471866</td>\n",
       "      <td>-0.302198</td>\n",
       "      <td>0.345745</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "            7         8         9  ...       152       153       154  \\\n",
       "0    0.145142  0.002124 -0.159163  ... -0.230463 -0.485368 -0.191395   \n",
       "1   -0.118192 -0.046173  0.073946  ... -0.192078 -0.175423 -0.107930   \n",
       "2    0.228773  0.017037 -0.210503  ... -0.222775 -0.037336 -0.168785   \n",
       "3    0.085666  0.008473 -0.097937  ... -0.145243 -0.078934 -0.129396   \n",
       "4    0.106967 -0.070199 -0.146756  ... -0.397356 -0.267826 -0.351554   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.037145 -0.034464 -0.364933   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.109154 -0.377837 -0.633505   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.034463 -0.176934 -0.180343   \n",
       "158  0.509372  0.196520  0.353393  ... -0.138953 -0.349398 -0.807273   \n",
       "159  0.352581  0.013532  0.110845  ...  0.059789 -0.026417 -0.399564   \n",
       "\n",
       "          155       156       157       158       159  Valence  Arousal  \n",
       "0   -0.101293 -0.149035  0.214239  0.229560  0.270990        1        1  \n",
       "1   -0.014033 -0.125412  0.324328  0.259344  0.265191        1        1  \n",
       "2   -0.081766 -0.119669  0.322914  0.314184  0.348474        1        1  \n",
       "3   -0.067172 -0.095273  0.140745  0.105676  0.187967        1        1  \n",
       "4   -0.208562 -0.317293  0.453197  0.434129  0.491896        0        1  \n",
       "..        ...       ...       ...       ...       ...      ...      ...  \n",
       "155 -0.534069  0.096746 -0.423109 -0.314202  0.111795        0        0  \n",
       "156 -0.732398  0.015434 -0.657737 -0.563958  0.154532        0        0  \n",
       "157 -0.272553 -0.011187 -0.350077 -0.328384  0.044254        0        1  \n",
       "158 -1.163223  0.006002 -0.885491 -0.757759  0.288144        0        0  \n",
       "159 -0.691021  0.283223 -0.471866 -0.302198  0.345745        0        1  \n",
       "\n",
       "[160 rows x 162 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f006f9f",
   "metadata": {},
   "source": [
    "# RED NEURONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619aabfd",
   "metadata": {},
   "source": [
    "# Division de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "087932d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = totalData.iloc[:, :-2]\n",
    "y = totalData[['Valence','Arousal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54c8a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.136242</td>\n",
       "      <td>-0.230463</td>\n",
       "      <td>-0.485368</td>\n",
       "      <td>-0.191395</td>\n",
       "      <td>-0.101293</td>\n",
       "      <td>-0.149035</td>\n",
       "      <td>0.214239</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>0.270990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134745</td>\n",
       "      <td>-0.213549</td>\n",
       "      <td>-0.192078</td>\n",
       "      <td>-0.175423</td>\n",
       "      <td>-0.107930</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>-0.125412</td>\n",
       "      <td>0.324328</td>\n",
       "      <td>0.259344</td>\n",
       "      <td>0.265191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125861</td>\n",
       "      <td>-0.327134</td>\n",
       "      <td>-0.222775</td>\n",
       "      <td>-0.037336</td>\n",
       "      <td>-0.168785</td>\n",
       "      <td>-0.081766</td>\n",
       "      <td>-0.119669</td>\n",
       "      <td>0.322914</td>\n",
       "      <td>0.314184</td>\n",
       "      <td>0.348474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053120</td>\n",
       "      <td>-0.125716</td>\n",
       "      <td>-0.145243</td>\n",
       "      <td>-0.078934</td>\n",
       "      <td>-0.129396</td>\n",
       "      <td>-0.067172</td>\n",
       "      <td>-0.095273</td>\n",
       "      <td>0.140745</td>\n",
       "      <td>0.105676</td>\n",
       "      <td>0.187967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329096</td>\n",
       "      <td>-0.189732</td>\n",
       "      <td>-0.397356</td>\n",
       "      <td>-0.267826</td>\n",
       "      <td>-0.351554</td>\n",
       "      <td>-0.208562</td>\n",
       "      <td>-0.317293</td>\n",
       "      <td>0.453197</td>\n",
       "      <td>0.434129</td>\n",
       "      <td>0.491896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749911</td>\n",
       "      <td>-0.935890</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>-0.034464</td>\n",
       "      <td>-0.364933</td>\n",
       "      <td>-0.534069</td>\n",
       "      <td>0.096746</td>\n",
       "      <td>-0.423109</td>\n",
       "      <td>-0.314202</td>\n",
       "      <td>0.111795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821177</td>\n",
       "      <td>-0.843650</td>\n",
       "      <td>0.109154</td>\n",
       "      <td>-0.377837</td>\n",
       "      <td>-0.633505</td>\n",
       "      <td>-0.732398</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>-0.657737</td>\n",
       "      <td>-0.563958</td>\n",
       "      <td>0.154532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404489</td>\n",
       "      <td>-0.477506</td>\n",
       "      <td>0.034463</td>\n",
       "      <td>-0.176934</td>\n",
       "      <td>-0.180343</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-0.011187</td>\n",
       "      <td>-0.350077</td>\n",
       "      <td>-0.328384</td>\n",
       "      <td>0.044254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128420</td>\n",
       "      <td>-1.154964</td>\n",
       "      <td>-0.138953</td>\n",
       "      <td>-0.349398</td>\n",
       "      <td>-0.807273</td>\n",
       "      <td>-1.163223</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>-0.885491</td>\n",
       "      <td>-0.757759</td>\n",
       "      <td>0.288144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664642</td>\n",
       "      <td>-0.657028</td>\n",
       "      <td>0.059789</td>\n",
       "      <td>-0.026417</td>\n",
       "      <td>-0.399564</td>\n",
       "      <td>-0.691021</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>-0.471866</td>\n",
       "      <td>-0.302198</td>\n",
       "      <td>0.345745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "          7         8         9    ...       150       151       152  \\\n",
       "0    0.145142  0.002124 -0.159163  ...  0.147541 -0.136242 -0.230463   \n",
       "1   -0.118192 -0.046173  0.073946  ...  0.134745 -0.213549 -0.192078   \n",
       "2    0.228773  0.017037 -0.210503  ...  0.125861 -0.327134 -0.222775   \n",
       "3    0.085666  0.008473 -0.097937  ...  0.053120 -0.125716 -0.145243   \n",
       "4    0.106967 -0.070199 -0.146756  ...  0.329096 -0.189732 -0.397356   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.749911 -0.935890  0.037145   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.821177 -0.843650  0.109154   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.404489 -0.477506  0.034463   \n",
       "158  0.509372  0.196520  0.353393  ...  1.128420 -1.154964 -0.138953   \n",
       "159  0.352581  0.013532  0.110845  ...  0.664642 -0.657028  0.059789   \n",
       "\n",
       "          153       154       155       156       157       158       159  \n",
       "0   -0.485368 -0.191395 -0.101293 -0.149035  0.214239  0.229560  0.270990  \n",
       "1   -0.175423 -0.107930 -0.014033 -0.125412  0.324328  0.259344  0.265191  \n",
       "2   -0.037336 -0.168785 -0.081766 -0.119669  0.322914  0.314184  0.348474  \n",
       "3   -0.078934 -0.129396 -0.067172 -0.095273  0.140745  0.105676  0.187967  \n",
       "4   -0.267826 -0.351554 -0.208562 -0.317293  0.453197  0.434129  0.491896  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "155 -0.034464 -0.364933 -0.534069  0.096746 -0.423109 -0.314202  0.111795  \n",
       "156 -0.377837 -0.633505 -0.732398  0.015434 -0.657737 -0.563958  0.154532  \n",
       "157 -0.176934 -0.180343 -0.272553 -0.011187 -0.350077 -0.328384  0.044254  \n",
       "158 -0.349398 -0.807273 -1.163223  0.006002 -0.885491 -0.757759  0.288144  \n",
       "159 -0.026417 -0.399564 -0.691021  0.283223 -0.471866 -0.302198  0.345745  \n",
       "\n",
       "[160 rows x 160 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a97e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Valence  Arousal\n",
       "0          1        1\n",
       "1          1        1\n",
       "2          1        1\n",
       "3          1        1\n",
       "4          0        1\n",
       "..       ...      ...\n",
       "155        0        0\n",
       "156        0        0\n",
       "157        0        1\n",
       "158        0        0\n",
       "159        0        1\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afb4fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e86b73",
   "metadata": {},
   "source": [
    "# CREACION DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb036340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04d48f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=160, activation='relu'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41e64bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 8ms/step - loss: 0.3627 - binary_accuracy: 0.4821\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3268 - binary_accuracy: 0.4821\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2831 - binary_accuracy: 0.5268\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2654 - binary_accuracy: 0.5446\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2567 - binary_accuracy: 0.5446\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2471 - binary_accuracy: 0.5536\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2547 - binary_accuracy: 0.5357\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2504 - binary_accuracy: 0.5625\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2490 - binary_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2488 - binary_accuracy: 0.5625\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2507 - binary_accuracy: 0.5357\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2502 - binary_accuracy: 0.5357\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2500 - binary_accuracy: 0.5357\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2496 - binary_accuracy: 0.5357\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2486 - binary_accuracy: 0.5446\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2464 - binary_accuracy: 0.5446\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2449 - binary_accuracy: 0.5446\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2427 - binary_accuracy: 0.5446\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2426 - binary_accuracy: 0.5446\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2420 - binary_accuracy: 0.5446\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2422 - binary_accuracy: 0.5446\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2412 - binary_accuracy: 0.5446\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2412 - binary_accuracy: 0.5446\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2428 - binary_accuracy: 0.5446\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2431 - binary_accuracy: 0.5446\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2437 - binary_accuracy: 0.5446\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2423 - binary_accuracy: 0.5446\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2413 - binary_accuracy: 0.5446\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2420 - binary_accuracy: 0.5446\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2421 - binary_accuracy: 0.5446\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2419 - binary_accuracy: 0.5536\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2417 - binary_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2416 - binary_accuracy: 0.5714\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2416 - binary_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2413 - binary_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2413 - binary_accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2411 - binary_accuracy: 0.5714\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2411 - binary_accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2410 - binary_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2408 - binary_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2407 - binary_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2406 - binary_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2406 - binary_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2406 - binary_accuracy: 0.5714\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2404 - binary_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2403 - binary_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2403 - binary_accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2402 - binary_accuracy: 0.5714\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2402 - binary_accuracy: 0.5714\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2403 - binary_accuracy: 0.5714\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2401 - binary_accuracy: 0.5714\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2403 - binary_accuracy: 0.5714\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2401 - binary_accuracy: 0.5714\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2399 - binary_accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2399 - binary_accuracy: 0.5714\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2398 - binary_accuracy: 0.5714\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2398 - binary_accuracy: 0.5714\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2398 - binary_accuracy: 0.5714\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2396 - binary_accuracy: 0.5893\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2395 - binary_accuracy: 0.5982\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2397 - binary_accuracy: 0.5982\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2395 - binary_accuracy: 0.5982\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2398 - binary_accuracy: 0.5982\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2395 - binary_accuracy: 0.5982\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2394 - binary_accuracy: 0.5982\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2395 - binary_accuracy: 0.5982\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2394 - binary_accuracy: 0.5982\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2393 - binary_accuracy: 0.5982\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2393 - binary_accuracy: 0.5982\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2393 - binary_accuracy: 0.5982\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2393 - binary_accuracy: 0.5982\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2394 - binary_accuracy: 0.5982\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2392 - binary_accuracy: 0.5982\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2393 - binary_accuracy: 0.5982\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2396 - binary_accuracy: 0.5982\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2395 - binary_accuracy: 0.5982\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2395 - binary_accuracy: 0.5982\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2396 - binary_accuracy: 0.5982\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2393 - binary_accuracy: 0.5982\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2392 - binary_accuracy: 0.5982\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2391 - binary_accuracy: 0.5982\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2390 - binary_accuracy: 0.5982\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2389 - binary_accuracy: 0.5982\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2389 - binary_accuracy: 0.5982\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2390 - binary_accuracy: 0.5982\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2392 - binary_accuracy: 0.5982\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2390 - binary_accuracy: 0.5982\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2389 - binary_accuracy: 0.5982\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 408us/step - loss: 0.2389 - binary_accuracy: 0.5982\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2389 - binary_accuracy: 0.5982\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2387 - binary_accuracy: 0.5982\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2388 - binary_accuracy: 0.5982\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2387 - binary_accuracy: 0.5982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd8ef2ffa0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b8227c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2387 - binary_accuracy: 0.5982\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "134eea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step - loss: 0.2459 - binary_accuracy: 0.5208\n",
      "Precisión del modelo en los datos de prueba: 0.5208333134651184\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Precisión del modelo en los datos de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566923b",
   "metadata": {},
   "source": [
    "# NORMALIZACION DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85a163dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Crea un objeto StandardScaler para normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "# Ajusta el objeto scaler al conjunto de datos de entrenamiento\n",
    "scaler.fit(x_train)\n",
    "# Normaliza los datos de entrenamiento y de prueba utilizando el objeto scaler\n",
    "x_train = scaler.transform(x_train)\n",
    "# Ajusta el objeto scaler al conjunto de datos de entrenamiento\n",
    "scaler.fit(x_test)\n",
    "# Normaliza los datos de entrenamiento y de prueba utilizando el objeto scaler\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "95a21cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=160, activation='relu'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40e73584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.3299 - binary_accuracy: 0.4821\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2848 - binary_accuracy: 0.4911\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2546 - binary_accuracy: 0.5536\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2388 - binary_accuracy: 0.5893\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2338 - binary_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2286 - binary_accuracy: 0.6071\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2243 - binary_accuracy: 0.6161\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2188 - binary_accuracy: 0.6429\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2154 - binary_accuracy: 0.6607\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2106 - binary_accuracy: 0.6607\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2073 - binary_accuracy: 0.6875\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2032 - binary_accuracy: 0.7054\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1997 - binary_accuracy: 0.7143\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1966 - binary_accuracy: 0.7054\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1931 - binary_accuracy: 0.7321\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1899 - binary_accuracy: 0.7321\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1863 - binary_accuracy: 0.7232\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1837 - binary_accuracy: 0.7321\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1805 - binary_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1781 - binary_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1753 - binary_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1727 - binary_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1700 - binary_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1678 - binary_accuracy: 0.7589\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1660 - binary_accuracy: 0.7589\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1639 - binary_accuracy: 0.7589\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1620 - binary_accuracy: 0.7589\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1596 - binary_accuracy: 0.7589\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1582 - binary_accuracy: 0.7589\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1566 - binary_accuracy: 0.7589\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1548 - binary_accuracy: 0.7589\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1534 - binary_accuracy: 0.7589\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 990us/step - loss: 0.1518 - binary_accuracy: 0.7589\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1506 - binary_accuracy: 0.7589\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1491 - binary_accuracy: 0.7589\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1482 - binary_accuracy: 0.7589\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1472 - binary_accuracy: 0.7589\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1459 - binary_accuracy: 0.7589\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1452 - binary_accuracy: 0.7589\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1437 - binary_accuracy: 0.7589\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1427 - binary_accuracy: 0.7589\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1420 - binary_accuracy: 0.7589\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1409 - binary_accuracy: 0.7589\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1400 - binary_accuracy: 0.7589\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1395 - binary_accuracy: 0.7589\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1388 - binary_accuracy: 0.7589\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1379 - binary_accuracy: 0.7589\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1373 - binary_accuracy: 0.7589\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1368 - binary_accuracy: 0.7589\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1361 - binary_accuracy: 0.7589\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1354 - binary_accuracy: 0.7589\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1349 - binary_accuracy: 0.7589\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1345 - binary_accuracy: 0.7589\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1338 - binary_accuracy: 0.7589\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1334 - binary_accuracy: 0.7589\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1332 - binary_accuracy: 0.7589\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1325 - binary_accuracy: 0.7589\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1323 - binary_accuracy: 0.7589\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1319 - binary_accuracy: 0.7589\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1313 - binary_accuracy: 0.7589\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1308 - binary_accuracy: 0.7589\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1305 - binary_accuracy: 0.7589\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1301 - binary_accuracy: 0.7589\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1298 - binary_accuracy: 0.7589\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1294 - binary_accuracy: 0.7589\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1291 - binary_accuracy: 0.7589\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1288 - binary_accuracy: 0.7589\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1285 - binary_accuracy: 0.7589\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1282 - binary_accuracy: 0.7589\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1279 - binary_accuracy: 0.7589\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1277 - binary_accuracy: 0.7589\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1274 - binary_accuracy: 0.7589\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1271 - binary_accuracy: 0.7589\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1269 - binary_accuracy: 0.7589\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1266 - binary_accuracy: 0.7589\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1264 - binary_accuracy: 0.7589\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1261 - binary_accuracy: 0.7589\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1258 - binary_accuracy: 0.7589\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1257 - binary_accuracy: 0.7589\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1254 - binary_accuracy: 0.7589\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1253 - binary_accuracy: 0.7589\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1251 - binary_accuracy: 0.7589\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1249 - binary_accuracy: 0.7589\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1247 - binary_accuracy: 0.7589\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1246 - binary_accuracy: 0.7589\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1245 - binary_accuracy: 0.7589\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1243 - binary_accuracy: 0.7589\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1243 - binary_accuracy: 0.7589\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1241 - binary_accuracy: 0.7589\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1239 - binary_accuracy: 0.7589\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1238 - binary_accuracy: 0.7589\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1237 - binary_accuracy: 0.7589\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1235 - binary_accuracy: 0.7589\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1235 - binary_accuracy: 0.7589\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1236 - binary_accuracy: 0.7589\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1233 - binary_accuracy: 0.7589\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1234 - binary_accuracy: 0.7589\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1233 - binary_accuracy: 0.7589\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 334us/step - loss: 0.1232 - binary_accuracy: 0.7589\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1232 - binary_accuracy: 0.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd9223f880>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fae50e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1228 - binary_accuracy: 0.7589\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17b4f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 947us/step - loss: 0.3038 - binary_accuracy: 0.5833\n",
      "Precisión del modelo en los datos de prueba: 0.5833333134651184\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Precisión del modelo en los datos de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423376ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
