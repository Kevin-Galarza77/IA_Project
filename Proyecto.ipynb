{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba05469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis, skew\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09991070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    x = pickle._Unpickler(open(filename,'rb'))\n",
    "    x.encoding = 'latin1'\n",
    "    p = x.load()\n",
    "    return p\n",
    "\n",
    "files = []\n",
    "for n in range(12,16):\n",
    "    s = 's'\n",
    "    if n<10:\n",
    "        s+='0'\n",
    "    s += str(n)+'.dat'\n",
    "    files.append(s)\n",
    "\n",
    "labels = []\n",
    "data   = []\n",
    "for i in files:\n",
    "    trial = read_file(i)\n",
    "    labels.append(trial['labels'])\n",
    "    data.append(trial['data'])\n",
    "    \n",
    "    \n",
    "labels = np.array(labels)\n",
    "labels = labels.flatten()\n",
    "labels = labels.reshape(160, 4)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "data = data.flatten()\n",
    "data = data.reshape(160, 40, 8064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4247de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1755f165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 40, 8064)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df739ce1",
   "metadata": {},
   "source": [
    "#  One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f065a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valenciaData = labels[:, :1]\n",
    "arousalData  = labels[:,1:2]\n",
    "medianValencia = np.median(valenciaData)\n",
    "medianArousle  = np.median(arousalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f8726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoding(valor,median):\n",
    "    if valor >= median:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75e578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFValencia = []\n",
    "for i in valenciaData:\n",
    "    DFValencia.append([OneHotEncoding(i[0],medianValencia)])\n",
    "    \n",
    "DFArousal = []\n",
    "for i in arousalData:\n",
    "    DFArousal.append([OneHotEncoding(i[0],medianArousle)])\n",
    "\n",
    "DFValencia = pd.DataFrame(data =DFValencia,columns=['Valence'])\n",
    "DFArousal = pd.DataFrame(data =DFArousal,columns=['Arousal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45e44f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Valence  Arousal\n",
       "0          1        1\n",
       "1          1        1\n",
       "2          1        1\n",
       "3          1        1\n",
       "4          0        1\n",
       "..       ...      ...\n",
       "155        0        0\n",
       "156        0        0\n",
       "157        0        1\n",
       "158        0        0\n",
       "159        0        1\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ETIQUETA VALENCIA Y ETIQUETA AROUSEL\n",
    "DFValenciaArrousel = pd.concat([DFValencia,DFArousal],axis=1)\n",
    "DFValenciaArrousel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0a9ed",
   "metadata": {},
   "source": [
    "# Considerar únicamente 32 de los 40 canales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2c1ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 32, 8064)\n"
     ]
    }
   ],
   "source": [
    "egg_data = []\n",
    "for i in range (len(data)):\n",
    "    for j in range (32):\n",
    "        egg_data.append(data[i,j])\n",
    "egg_data = np.reshape(egg_data, (len(data),32,len(data[0,0]))) #(160, 32, 8064)\n",
    "print(egg_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15832d8e",
   "metadata": {},
   "source": [
    "# Extraer características de la data (media, varianza, mediana, curtosis,skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e5cb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371836</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>-0.663144</td>\n",
       "      <td>0.902769</td>\n",
       "      <td>-0.298318</td>\n",
       "      <td>-0.325642</td>\n",
       "      <td>-0.407584</td>\n",
       "      <td>0.398354</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>0.324193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>0.308096</td>\n",
       "      <td>0.060805</td>\n",
       "      <td>-0.056290</td>\n",
       "      <td>-0.085238</td>\n",
       "      <td>0.196436</td>\n",
       "      <td>-0.030506</td>\n",
       "      <td>-0.391325</td>\n",
       "      <td>-0.196199</td>\n",
       "      <td>-0.157996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222298</td>\n",
       "      <td>0.159388</td>\n",
       "      <td>-0.387562</td>\n",
       "      <td>0.183835</td>\n",
       "      <td>-0.292046</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>-0.470487</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.279082</td>\n",
       "      <td>0.302206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218251</td>\n",
       "      <td>0.164955</td>\n",
       "      <td>-0.247915</td>\n",
       "      <td>0.199474</td>\n",
       "      <td>-0.249897</td>\n",
       "      <td>-0.218154</td>\n",
       "      <td>-0.169720</td>\n",
       "      <td>0.257110</td>\n",
       "      <td>0.239160</td>\n",
       "      <td>0.244657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048290</td>\n",
       "      <td>0.106923</td>\n",
       "      <td>-0.001407</td>\n",
       "      <td>0.385465</td>\n",
       "      <td>0.185654</td>\n",
       "      <td>-0.104524</td>\n",
       "      <td>0.277236</td>\n",
       "      <td>0.121565</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.091230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151505</td>\n",
       "      <td>-0.073370</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>-0.024246</td>\n",
       "      <td>-0.261753</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.130394</td>\n",
       "      <td>-0.168163</td>\n",
       "      <td>-0.171839</td>\n",
       "      <td>-0.101694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531636</td>\n",
       "      <td>-0.578895</td>\n",
       "      <td>0.047247</td>\n",
       "      <td>0.181854</td>\n",
       "      <td>-0.499092</td>\n",
       "      <td>-1.441206</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>-0.516149</td>\n",
       "      <td>-0.285021</td>\n",
       "      <td>0.025439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178256</td>\n",
       "      <td>-0.207073</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.197028</td>\n",
       "      <td>-0.213354</td>\n",
       "      <td>-0.348560</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>-0.408333</td>\n",
       "      <td>-0.071239</td>\n",
       "      <td>-0.011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286763</td>\n",
       "      <td>0.352991</td>\n",
       "      <td>-0.054454</td>\n",
       "      <td>-0.031426</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.825504</td>\n",
       "      <td>-0.089650</td>\n",
       "      <td>0.363388</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>-0.177031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115951</td>\n",
       "      <td>-0.010063</td>\n",
       "      <td>-0.084788</td>\n",
       "      <td>-0.156996</td>\n",
       "      <td>-0.027193</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>-0.320651</td>\n",
       "      <td>-0.141771</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>-0.243399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "           7         8         9   ...        86        87        88  \\\n",
       "0    0.145142  0.002124 -0.159163  ...  0.371836  0.003666 -0.663144   \n",
       "1   -0.118192 -0.046173  0.073946  ... -0.000851  0.308096  0.060805   \n",
       "2    0.228773  0.017037 -0.210503  ...  0.222298  0.159388 -0.387562   \n",
       "3    0.085666  0.008473 -0.097937  ...  0.218251  0.164955 -0.247915   \n",
       "4    0.106967 -0.070199 -0.146756  ...  0.048290  0.106923 -0.001407   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.151505 -0.073370  0.048221   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.531636 -0.578895  0.047247   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.178256 -0.207073  0.025205   \n",
       "158  0.509372  0.196520  0.353393  ... -0.286763  0.352991 -0.054454   \n",
       "159  0.352581  0.013532  0.110845  ... -0.115951 -0.010063 -0.084788   \n",
       "\n",
       "           89        90        91        92        93        94        95  \n",
       "0    0.902769 -0.298318 -0.325642 -0.407584  0.398354  0.250279  0.324193  \n",
       "1   -0.056290 -0.085238  0.196436 -0.030506 -0.391325 -0.196199 -0.157996  \n",
       "2    0.183835 -0.292046 -0.204235 -0.470487  0.113448  0.279082  0.302206  \n",
       "3    0.199474 -0.249897 -0.218154 -0.169720  0.257110  0.239160  0.244657  \n",
       "4    0.385465  0.185654 -0.104524  0.277236  0.121565  0.018871  0.091230  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "155 -0.024246 -0.261753 -0.042488 -0.130394 -0.168163 -0.171839 -0.101694  \n",
       "156  0.181854 -0.499092 -1.441206 -0.023781 -0.516149 -0.285021  0.025439  \n",
       "157  0.197028 -0.213354 -0.348560  0.006054 -0.408333 -0.071239 -0.011023  \n",
       "158 -0.031426  0.205749  0.825504 -0.089650  0.363388  0.321538 -0.177031  \n",
       "159 -0.156996 -0.027193  0.972184 -0.320651 -0.141771  0.026376 -0.243399  \n",
       "\n",
       "[160 rows x 96 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media     =  np.mean(egg_data, axis=2)\n",
    "varianza  =  np.var(egg_data, axis=2) \n",
    "mediana   =  np.median(egg_data, axis=2)\n",
    "curtosis  =  scipy.stats.kurtosis(egg_data, axis=2)\n",
    "asimetria =  scipy.stats.skew(egg_data, axis=2)\n",
    "totalData =  np.concatenate((media, varianza, mediana),axis=1) \n",
    "totalData =  pd.DataFrame(totalData)\n",
    "totalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b02e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.663144</td>\n",
       "      <td>0.902769</td>\n",
       "      <td>-0.298318</td>\n",
       "      <td>-0.325642</td>\n",
       "      <td>-0.407584</td>\n",
       "      <td>0.398354</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>0.324193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060805</td>\n",
       "      <td>-0.056290</td>\n",
       "      <td>-0.085238</td>\n",
       "      <td>0.196436</td>\n",
       "      <td>-0.030506</td>\n",
       "      <td>-0.391325</td>\n",
       "      <td>-0.196199</td>\n",
       "      <td>-0.157996</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387562</td>\n",
       "      <td>0.183835</td>\n",
       "      <td>-0.292046</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>-0.470487</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.279082</td>\n",
       "      <td>0.302206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247915</td>\n",
       "      <td>0.199474</td>\n",
       "      <td>-0.249897</td>\n",
       "      <td>-0.218154</td>\n",
       "      <td>-0.169720</td>\n",
       "      <td>0.257110</td>\n",
       "      <td>0.239160</td>\n",
       "      <td>0.244657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001407</td>\n",
       "      <td>0.385465</td>\n",
       "      <td>0.185654</td>\n",
       "      <td>-0.104524</td>\n",
       "      <td>0.277236</td>\n",
       "      <td>0.121565</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.091230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>-0.024246</td>\n",
       "      <td>-0.261753</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.130394</td>\n",
       "      <td>-0.168163</td>\n",
       "      <td>-0.171839</td>\n",
       "      <td>-0.101694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047247</td>\n",
       "      <td>0.181854</td>\n",
       "      <td>-0.499092</td>\n",
       "      <td>-1.441206</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>-0.516149</td>\n",
       "      <td>-0.285021</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.197028</td>\n",
       "      <td>-0.213354</td>\n",
       "      <td>-0.348560</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>-0.408333</td>\n",
       "      <td>-0.071239</td>\n",
       "      <td>-0.011023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054454</td>\n",
       "      <td>-0.031426</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.825504</td>\n",
       "      <td>-0.089650</td>\n",
       "      <td>0.363388</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>-0.177031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084788</td>\n",
       "      <td>-0.156996</td>\n",
       "      <td>-0.027193</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>-0.320651</td>\n",
       "      <td>-0.141771</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>-0.243399</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "            7         8         9  ...        88        89        90  \\\n",
       "0    0.145142  0.002124 -0.159163  ... -0.663144  0.902769 -0.298318   \n",
       "1   -0.118192 -0.046173  0.073946  ...  0.060805 -0.056290 -0.085238   \n",
       "2    0.228773  0.017037 -0.210503  ... -0.387562  0.183835 -0.292046   \n",
       "3    0.085666  0.008473 -0.097937  ... -0.247915  0.199474 -0.249897   \n",
       "4    0.106967 -0.070199 -0.146756  ... -0.001407  0.385465  0.185654   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.048221 -0.024246 -0.261753   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.047247  0.181854 -0.499092   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.025205  0.197028 -0.213354   \n",
       "158  0.509372  0.196520  0.353393  ... -0.054454 -0.031426  0.205749   \n",
       "159  0.352581  0.013532  0.110845  ... -0.084788 -0.156996 -0.027193   \n",
       "\n",
       "           91        92        93        94        95  Valence  Arousal  \n",
       "0   -0.325642 -0.407584  0.398354  0.250279  0.324193        1        1  \n",
       "1    0.196436 -0.030506 -0.391325 -0.196199 -0.157996        1        1  \n",
       "2   -0.204235 -0.470487  0.113448  0.279082  0.302206        1        1  \n",
       "3   -0.218154 -0.169720  0.257110  0.239160  0.244657        1        1  \n",
       "4   -0.104524  0.277236  0.121565  0.018871  0.091230        0        1  \n",
       "..        ...       ...       ...       ...       ...      ...      ...  \n",
       "155 -0.042488 -0.130394 -0.168163 -0.171839 -0.101694        0        0  \n",
       "156 -1.441206 -0.023781 -0.516149 -0.285021  0.025439        0        0  \n",
       "157 -0.348560  0.006054 -0.408333 -0.071239 -0.011023        0        1  \n",
       "158  0.825504 -0.089650  0.363388  0.321538 -0.177031        0        0  \n",
       "159  0.972184 -0.320651 -0.141771  0.026376 -0.243399        0        1  \n",
       "\n",
       "[160 rows x 98 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UNIMOS CON LA ETIQUETA VALENCIA Y ETIQUETA AROUSEL\n",
    "totalData = pd.concat([totalData,DFValenciaArrousel],axis=1)\n",
    "totalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371b8064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "totalData.isnull()\n",
    "sns.heatmap(totalData.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90eeb801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.663144</td>\n",
       "      <td>0.902769</td>\n",
       "      <td>-0.298318</td>\n",
       "      <td>-0.325642</td>\n",
       "      <td>-0.407584</td>\n",
       "      <td>0.398354</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>0.324193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060805</td>\n",
       "      <td>-0.056290</td>\n",
       "      <td>-0.085238</td>\n",
       "      <td>0.196436</td>\n",
       "      <td>-0.030506</td>\n",
       "      <td>-0.391325</td>\n",
       "      <td>-0.196199</td>\n",
       "      <td>-0.157996</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387562</td>\n",
       "      <td>0.183835</td>\n",
       "      <td>-0.292046</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>-0.470487</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.279082</td>\n",
       "      <td>0.302206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247915</td>\n",
       "      <td>0.199474</td>\n",
       "      <td>-0.249897</td>\n",
       "      <td>-0.218154</td>\n",
       "      <td>-0.169720</td>\n",
       "      <td>0.257110</td>\n",
       "      <td>0.239160</td>\n",
       "      <td>0.244657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001407</td>\n",
       "      <td>0.385465</td>\n",
       "      <td>0.185654</td>\n",
       "      <td>-0.104524</td>\n",
       "      <td>0.277236</td>\n",
       "      <td>0.121565</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.091230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>-0.024246</td>\n",
       "      <td>-0.261753</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.130394</td>\n",
       "      <td>-0.168163</td>\n",
       "      <td>-0.171839</td>\n",
       "      <td>-0.101694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047247</td>\n",
       "      <td>0.181854</td>\n",
       "      <td>-0.499092</td>\n",
       "      <td>-1.441206</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>-0.516149</td>\n",
       "      <td>-0.285021</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.197028</td>\n",
       "      <td>-0.213354</td>\n",
       "      <td>-0.348560</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>-0.408333</td>\n",
       "      <td>-0.071239</td>\n",
       "      <td>-0.011023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054454</td>\n",
       "      <td>-0.031426</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.825504</td>\n",
       "      <td>-0.089650</td>\n",
       "      <td>0.363388</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>-0.177031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084788</td>\n",
       "      <td>-0.156996</td>\n",
       "      <td>-0.027193</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>-0.320651</td>\n",
       "      <td>-0.141771</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>-0.243399</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "            7         8         9  ...        88        89        90  \\\n",
       "0    0.145142  0.002124 -0.159163  ... -0.663144  0.902769 -0.298318   \n",
       "1   -0.118192 -0.046173  0.073946  ...  0.060805 -0.056290 -0.085238   \n",
       "2    0.228773  0.017037 -0.210503  ... -0.387562  0.183835 -0.292046   \n",
       "3    0.085666  0.008473 -0.097937  ... -0.247915  0.199474 -0.249897   \n",
       "4    0.106967 -0.070199 -0.146756  ... -0.001407  0.385465  0.185654   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.048221 -0.024246 -0.261753   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.047247  0.181854 -0.499092   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.025205  0.197028 -0.213354   \n",
       "158  0.509372  0.196520  0.353393  ... -0.054454 -0.031426  0.205749   \n",
       "159  0.352581  0.013532  0.110845  ... -0.084788 -0.156996 -0.027193   \n",
       "\n",
       "           91        92        93        94        95  Valence  Arousal  \n",
       "0   -0.325642 -0.407584  0.398354  0.250279  0.324193        1        1  \n",
       "1    0.196436 -0.030506 -0.391325 -0.196199 -0.157996        1        1  \n",
       "2   -0.204235 -0.470487  0.113448  0.279082  0.302206        1        1  \n",
       "3   -0.218154 -0.169720  0.257110  0.239160  0.244657        1        1  \n",
       "4   -0.104524  0.277236  0.121565  0.018871  0.091230        0        1  \n",
       "..        ...       ...       ...       ...       ...      ...      ...  \n",
       "155 -0.042488 -0.130394 -0.168163 -0.171839 -0.101694        0        0  \n",
       "156 -1.441206 -0.023781 -0.516149 -0.285021  0.025439        0        0  \n",
       "157 -0.348560  0.006054 -0.408333 -0.071239 -0.011023        0        1  \n",
       "158  0.825504 -0.089650  0.363388  0.321538 -0.177031        0        0  \n",
       "159  0.972184 -0.320651 -0.141771  0.026376 -0.243399        0        1  \n",
       "\n",
       "[160 rows x 98 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f006f9f",
   "metadata": {},
   "source": [
    "# RED NEURONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619aabfd",
   "metadata": {},
   "source": [
    "# Division de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "087932d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = totalData.iloc[:, :-2]\n",
    "y = totalData[['Valence','Arousal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2adbeab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.074017</td>\n",
       "      <td>-0.285636</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.159163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371836</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>-0.663144</td>\n",
       "      <td>0.902769</td>\n",
       "      <td>-0.298318</td>\n",
       "      <td>-0.325642</td>\n",
       "      <td>-0.407584</td>\n",
       "      <td>0.398354</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>0.324193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.098578</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.103224</td>\n",
       "      <td>0.106441</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.173679</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>-0.118192</td>\n",
       "      <td>-0.046173</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>0.308096</td>\n",
       "      <td>0.060805</td>\n",
       "      <td>-0.056290</td>\n",
       "      <td>-0.085238</td>\n",
       "      <td>0.196436</td>\n",
       "      <td>-0.030506</td>\n",
       "      <td>-0.391325</td>\n",
       "      <td>-0.196199</td>\n",
       "      <td>-0.157996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357237</td>\n",
       "      <td>0.216536</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.141264</td>\n",
       "      <td>-0.122158</td>\n",
       "      <td>-0.414290</td>\n",
       "      <td>-0.482347</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.210503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222298</td>\n",
       "      <td>0.159388</td>\n",
       "      <td>-0.387562</td>\n",
       "      <td>0.183835</td>\n",
       "      <td>-0.292046</td>\n",
       "      <td>-0.204235</td>\n",
       "      <td>-0.470487</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.279082</td>\n",
       "      <td>0.302206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>-0.048039</td>\n",
       "      <td>0.085666</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.097937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218251</td>\n",
       "      <td>0.164955</td>\n",
       "      <td>-0.247915</td>\n",
       "      <td>0.199474</td>\n",
       "      <td>-0.249897</td>\n",
       "      <td>-0.218154</td>\n",
       "      <td>-0.169720</td>\n",
       "      <td>0.257110</td>\n",
       "      <td>0.239160</td>\n",
       "      <td>0.244657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225952</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.171093</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>-0.082453</td>\n",
       "      <td>-0.210313</td>\n",
       "      <td>-0.261041</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.070199</td>\n",
       "      <td>-0.146756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048290</td>\n",
       "      <td>0.106923</td>\n",
       "      <td>-0.001407</td>\n",
       "      <td>0.385465</td>\n",
       "      <td>0.185654</td>\n",
       "      <td>-0.104524</td>\n",
       "      <td>0.277236</td>\n",
       "      <td>0.121565</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.091230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-0.153143</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.113727</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>-0.179780</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.243677</td>\n",
       "      <td>-0.160029</td>\n",
       "      <td>-0.289743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151505</td>\n",
       "      <td>-0.073370</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>-0.024246</td>\n",
       "      <td>-0.261753</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.130394</td>\n",
       "      <td>-0.168163</td>\n",
       "      <td>-0.171839</td>\n",
       "      <td>-0.101694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.416808</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.388729</td>\n",
       "      <td>0.696510</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.268579</td>\n",
       "      <td>-1.349137</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531636</td>\n",
       "      <td>-0.578895</td>\n",
       "      <td>0.047247</td>\n",
       "      <td>0.181854</td>\n",
       "      <td>-0.499092</td>\n",
       "      <td>-1.441206</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>-0.516149</td>\n",
       "      <td>-0.285021</td>\n",
       "      <td>0.025439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.185910</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.096731</td>\n",
       "      <td>0.310776</td>\n",
       "      <td>-0.038999</td>\n",
       "      <td>-0.201541</td>\n",
       "      <td>-0.048862</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>-0.186267</td>\n",
       "      <td>-0.307484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178256</td>\n",
       "      <td>-0.207073</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.197028</td>\n",
       "      <td>-0.213354</td>\n",
       "      <td>-0.348560</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>-0.408333</td>\n",
       "      <td>-0.071239</td>\n",
       "      <td>-0.011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>-0.207203</td>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.062127</td>\n",
       "      <td>0.227403</td>\n",
       "      <td>0.150252</td>\n",
       "      <td>0.509372</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.353393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286763</td>\n",
       "      <td>0.352991</td>\n",
       "      <td>-0.054454</td>\n",
       "      <td>-0.031426</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.825504</td>\n",
       "      <td>-0.089650</td>\n",
       "      <td>0.363388</td>\n",
       "      <td>0.321538</td>\n",
       "      <td>-0.177031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>-0.169874</td>\n",
       "      <td>0.218832</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.275921</td>\n",
       "      <td>0.352581</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115951</td>\n",
       "      <td>-0.010063</td>\n",
       "      <td>-0.084788</td>\n",
       "      <td>-0.156996</td>\n",
       "      <td>-0.027193</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>-0.320651</td>\n",
       "      <td>-0.141771</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>-0.243399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.239718  0.139201 -0.003365 -0.094386 -0.074017 -0.285636 -0.335566   \n",
       "1   -0.098578  0.026670  0.103224  0.106441  0.029345  0.173679  0.160801   \n",
       "2    0.357237  0.216536 -0.020147 -0.141264 -0.122158 -0.414290 -0.482347   \n",
       "3    0.002980  0.051026  0.033575  0.043446  0.005714 -0.049259 -0.048039   \n",
       "4    0.225952  0.325248  0.171093  0.025920 -0.082453 -0.210313 -0.261041   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "155 -0.153143  0.054761  0.113727  0.231190  0.024728 -0.179780  0.013596   \n",
       "156 -0.416808  0.013242  0.388729  0.696510 -0.095986 -0.595338 -0.268579   \n",
       "157 -0.185910  0.013230  0.096731  0.310776 -0.038999 -0.201541 -0.048862   \n",
       "158  0.199764  0.040398 -0.207203 -0.200726  0.062127  0.227403  0.150252   \n",
       "159  0.073927  0.168315 -0.169874  0.218832 -0.058683  0.069050  0.275921   \n",
       "\n",
       "           7         8         9   ...        86        87        88  \\\n",
       "0    0.145142  0.002124 -0.159163  ...  0.371836  0.003666 -0.663144   \n",
       "1   -0.118192 -0.046173  0.073946  ... -0.000851  0.308096  0.060805   \n",
       "2    0.228773  0.017037 -0.210503  ...  0.222298  0.159388 -0.387562   \n",
       "3    0.085666  0.008473 -0.097937  ...  0.218251  0.164955 -0.247915   \n",
       "4    0.106967 -0.070199 -0.146756  ...  0.048290  0.106923 -0.001407   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "155 -0.243677 -0.160029 -0.289743  ...  0.151505 -0.073370  0.048221   \n",
       "156 -1.349137 -0.548055 -0.871668  ...  0.531636 -0.578895  0.047247   \n",
       "157 -0.391158 -0.186267 -0.307484  ...  0.178256 -0.207073  0.025205   \n",
       "158  0.509372  0.196520  0.353393  ... -0.286763  0.352991 -0.054454   \n",
       "159  0.352581  0.013532  0.110845  ... -0.115951 -0.010063 -0.084788   \n",
       "\n",
       "           89        90        91        92        93        94        95  \n",
       "0    0.902769 -0.298318 -0.325642 -0.407584  0.398354  0.250279  0.324193  \n",
       "1   -0.056290 -0.085238  0.196436 -0.030506 -0.391325 -0.196199 -0.157996  \n",
       "2    0.183835 -0.292046 -0.204235 -0.470487  0.113448  0.279082  0.302206  \n",
       "3    0.199474 -0.249897 -0.218154 -0.169720  0.257110  0.239160  0.244657  \n",
       "4    0.385465  0.185654 -0.104524  0.277236  0.121565  0.018871  0.091230  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "155 -0.024246 -0.261753 -0.042488 -0.130394 -0.168163 -0.171839 -0.101694  \n",
       "156  0.181854 -0.499092 -1.441206 -0.023781 -0.516149 -0.285021  0.025439  \n",
       "157  0.197028 -0.213354 -0.348560  0.006054 -0.408333 -0.071239 -0.011023  \n",
       "158 -0.031426  0.205749  0.825504 -0.089650  0.363388  0.321538 -0.177031  \n",
       "159 -0.156996 -0.027193  0.972184 -0.320651 -0.141771  0.026376 -0.243399  \n",
       "\n",
       "[160 rows x 96 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed748a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Valence  Arousal\n",
       "0          1        1\n",
       "1          1        1\n",
       "2          1        1\n",
       "3          1        1\n",
       "4          0        1\n",
       "..       ...      ...\n",
       "155        0        0\n",
       "156        0        0\n",
       "157        0        1\n",
       "158        0        0\n",
       "159        0        1\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c8eae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee823f71",
   "metadata": {},
   "source": [
    "# CREACION DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb036340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04d48f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=96, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41e64bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.4918 - binary_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5087 - binary_accuracy: 0.4911\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4815 - binary_accuracy: 0.5179\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4717 - binary_accuracy: 0.5268\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 862us/step - loss: 0.4683 - binary_accuracy: 0.5268\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4463 - binary_accuracy: 0.5536\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4659 - binary_accuracy: 0.5268\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4235 - binary_accuracy: 0.5625\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4174 - binary_accuracy: 0.5804\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4179 - binary_accuracy: 0.5804\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 672us/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 644us/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21db7f3ef70>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b8227c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - binary_accuracy: 0.5804\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34cea4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4583 - binary_accuracy: 0.5417\n",
      "Precisión del modelo en los datos de prueba: 0.5416666865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Precisión del modelo en los datos de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566923b",
   "metadata": {},
   "source": [
    "# NORMALIZACION DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd1d8aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crea un objeto StandardScaler para normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "# Ajusta el objeto scaler al conjunto de datos de entrenamiento\n",
    "scaler.fit(x_train)\n",
    "# Normaliza los datos de entrenamiento y de prueba utilizando el objeto scaler\n",
    "x_train = scaler.transform(x_train)\n",
    "# Ajusta el objeto scaler al conjunto de datos de entrenamiento\n",
    "scaler.fit(x_test)\n",
    "# Normaliza los datos de entrenamiento y de prueba utilizando el objeto scaler\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9dcb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=96, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40e73584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 7ms/step - loss: 0.3032 - binary_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2897 - binary_accuracy: 0.5268\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2801 - binary_accuracy: 0.5357\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2711 - binary_accuracy: 0.5536\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2623 - binary_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2535 - binary_accuracy: 0.5893\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 566us/step - loss: 0.2465 - binary_accuracy: 0.5982\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2402 - binary_accuracy: 0.5982\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2357 - binary_accuracy: 0.6071\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2338 - binary_accuracy: 0.6161\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 901us/step - loss: 0.2319 - binary_accuracy: 0.6161\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2300 - binary_accuracy: 0.6250\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2286 - binary_accuracy: 0.6250\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 517us/step - loss: 0.2272 - binary_accuracy: 0.6161\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2256 - binary_accuracy: 0.6161\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2240 - binary_accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2224 - binary_accuracy: 0.6339\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2212 - binary_accuracy: 0.6518\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2200 - binary_accuracy: 0.6518\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2189 - binary_accuracy: 0.6607\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2177 - binary_accuracy: 0.6607\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2165 - binary_accuracy: 0.6696\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2156 - binary_accuracy: 0.6696\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2145 - binary_accuracy: 0.6696\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2135 - binary_accuracy: 0.6786\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2122 - binary_accuracy: 0.6786\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2113 - binary_accuracy: 0.6786\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2104 - binary_accuracy: 0.6786\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2095 - binary_accuracy: 0.6786\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2088 - binary_accuracy: 0.6696\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2075 - binary_accuracy: 0.6786\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2066 - binary_accuracy: 0.6786\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2059 - binary_accuracy: 0.6786\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2048 - binary_accuracy: 0.6786\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2039 - binary_accuracy: 0.6875\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2031 - binary_accuracy: 0.6875\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2023 - binary_accuracy: 0.6964\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2015 - binary_accuracy: 0.6964\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.2010 - binary_accuracy: 0.7054\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2002 - binary_accuracy: 0.7054\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1998 - binary_accuracy: 0.7054\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1988 - binary_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1980 - binary_accuracy: 0.7143\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1974 - binary_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1967 - binary_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1963 - binary_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1955 - binary_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1951 - binary_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1946 - binary_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1938 - binary_accuracy: 0.7232\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1934 - binary_accuracy: 0.7232\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1928 - binary_accuracy: 0.7232\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1922 - binary_accuracy: 0.7232\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1916 - binary_accuracy: 0.7232\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1911 - binary_accuracy: 0.7232\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1907 - binary_accuracy: 0.7232\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1902 - binary_accuracy: 0.7232\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1896 - binary_accuracy: 0.7232\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1891 - binary_accuracy: 0.7232\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1885 - binary_accuracy: 0.7232\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1881 - binary_accuracy: 0.7232\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1879 - binary_accuracy: 0.7232\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1872 - binary_accuracy: 0.7232\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1869 - binary_accuracy: 0.7232\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1865 - binary_accuracy: 0.7232\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1860 - binary_accuracy: 0.7232\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1854 - binary_accuracy: 0.7232\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1850 - binary_accuracy: 0.7232\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1846 - binary_accuracy: 0.7232\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1840 - binary_accuracy: 0.7232\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1835 - binary_accuracy: 0.7232\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1835 - binary_accuracy: 0.7232\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 950us/step - loss: 0.1828 - binary_accuracy: 0.7232\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1823 - binary_accuracy: 0.7232\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1818 - binary_accuracy: 0.7232\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1817 - binary_accuracy: 0.7232\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1812 - binary_accuracy: 0.7232\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 721us/step - loss: 0.1807 - binary_accuracy: 0.7232\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 0s/step - loss: 0.1804 - binary_accuracy: 0.7232\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1799 - binary_accuracy: 0.7232\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1796 - binary_accuracy: 0.7232\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1792 - binary_accuracy: 0.7232\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1786 - binary_accuracy: 0.7232\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1783 - binary_accuracy: 0.7232\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1780 - binary_accuracy: 0.7232\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1777 - binary_accuracy: 0.7232\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1773 - binary_accuracy: 0.7232\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 844us/step - loss: 0.1769 - binary_accuracy: 0.7232\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1766 - binary_accuracy: 0.7232\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1762 - binary_accuracy: 0.7232\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1759 - binary_accuracy: 0.7232\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1757 - binary_accuracy: 0.7232\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1753 - binary_accuracy: 0.7321\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1748 - binary_accuracy: 0.7321\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 456us/step - loss: 0.1745 - binary_accuracy: 0.7321\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1743 - binary_accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1739 - binary_accuracy: 0.7232\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1735 - binary_accuracy: 0.7232\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1731 - binary_accuracy: 0.7321\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1729 - binary_accuracy: 0.7232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dba2e0d30>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fae50e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1725 - binary_accuracy: 0.7232\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20c4ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2805 - binary_accuracy: 0.5417\n",
      "Precisión del modelo en los datos de prueba: 0.5416666865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Precisión del modelo en los datos de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04fb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
